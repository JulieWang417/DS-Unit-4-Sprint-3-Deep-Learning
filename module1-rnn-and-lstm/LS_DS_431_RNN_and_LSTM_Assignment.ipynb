{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ltj1je1fp5rO"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
    "\n",
    "r = requests.request('POST', url)\n",
    "\n",
    "r.encoding = r.apparent_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139330\n"
     ]
    }
   ],
   "source": [
    "texts = r.text.replace('\\r','').split('\\n')\n",
    "\n",
    "t = []\n",
    "for text in texts:\n",
    "    if text != '':\n",
    "        t.append(text)\n",
    "        \n",
    "print(len(t))\n",
    "t0 = t[63:(len(t)-285)]\n",
    "\n",
    "data = \"\"\n",
    "for text in t0:\n",
    "    data += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5385645"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE SONNETS                    1From fairest creatures we desire increase,That thereby beauty’s rose might never die,But as the riper should by time decease,His tender heir might bear his memory:But t'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\t', ' ', '!', '\"', '&', \"'\", '(', ')', '*', ',']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Counting Chars\n",
    "#set help to create a list with out duplicate values.\n",
    "chars = sorted(list(set(data)))\n",
    "chars[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chars (index, character)\n",
    "# Save indices into a dictionary\n",
    "#Enumerate helps to add index to list\n",
    "\n",
    "#char_indices = dict((c,i) for i, c in enumerate(chars))\n",
    "\n",
    "# Lookup Tables\n",
    "char_int = {c:i for i, c in enumerate(chars)} \n",
    "int_char = {i:c for i, c in enumerate(chars)} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences:  1077121\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##### Create the sequence data\n",
    "\n",
    "maxlen = 40  #We set that we're going to send 39 characters and it's going to predict the character 40\n",
    "step = 5  # we decide to say that each 5 characteres are going to be a sentence\n",
    "\n",
    "encoded = [char_int[s] for s in data]\n",
    "\n",
    "sequences = [] # Each element is 40 chars long  # X inputs\n",
    "next_char = [] # One element for each sequence    # Y predictions\n",
    "\n",
    "for i in range(0, len(encoded) - maxlen, step):\n",
    "    \n",
    "    sequences.append(encoded[i : i + maxlen])\n",
    "    next_char.append(encoded[i + maxlen])\n",
    "    \n",
    "print('sequences: ', len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify x & y\n",
    "# samples len(sentences)\n",
    "# len(chars) how many unique characteres \n",
    "# maxlen \n",
    "\n",
    "#We're going to create the arrays with zeros ( it's transformed to False with type bool)  with the correct size that we need it.\n",
    "\n",
    "\n",
    "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i,t,char] = 1\n",
    "        \n",
    "    y[i, next_char[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1077121, 40, 101), (1077121, 101))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 101)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model: a single LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / 1\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    \n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    \n",
    "    generated = ''\n",
    "    \n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    \n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "    \n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_int[char]] = 1\n",
    "            \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds)\n",
    "        next_char = int_char[next_index]\n",
    "        \n",
    "        sentence = sentence[1:] + next_char\n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1077121 samples\n",
      "Epoch 1/5\n",
      "1077120/1077121 [============================>.] - ETA: 0s - loss: 2.2676\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: \"ns a United States copyright in these wo\"\n",
      "ns a United States copyright in these wo loy it faid, on, lave necour Capsace, I gut I  I the or fatt fyales preneat you snbont you GeactyeruresHow I ery weallwerbewing fory, ank hav' the woll thet in the guit canh have thus my a thouse,    Nade in ong tr‘enter botine do prodionds? Jrute thou stire hon it.  TAHS RYINLA. Camy PELTEIW.O, the blove nht art it, thrugge a ruons:Arowns to hast in caltiight.Fearthimo hame 'I hims it unat mants\n",
      "1077121/1077121 [==============================] - 493s 458us/sample - loss: 2.2676\n",
      "Epoch 2/5\n",
      "1077120/1077121 [============================>.] - ETA: 0s - loss: 1.9434\n",
      "----- Generating text after Epoch: 1\n",
      "----- Generating with seed: \" that no one owns a United States copyri\"\n",
      " that no one owns a United States copyriantan of sell I that is.  Them    Queze which what so a plook' dise deiss, no your drem be to will my the wound be mepectiod?Wither. Enter LightBowe’t,Fow Frient Half lear follis’d op shall, stwick out thou manger a timas's may cumpo. Stist ain, ay groy dotsong of nice do are wisher plake hants do mody,Craltet or friin ro tullioniur sives by filly pleass, pernitooa; so a praycior ant lake;    Ruma\n",
      "1077121/1077121 [==============================] - 536s 498us/sample - loss: 1.9434\n",
      "Epoch 3/5\n",
      "1077120/1077121 [============================>.] - ETA: 0s - loss: 1.8352\n",
      "----- Generating text after Epoch: 2\n",
      "----- Generating with seed: \"that no one owns a United States copyrig\"\n",
      "that no one owns a United States copyrigus, made uf who woll.ROSEN.' Whe all- But thee and I murr;Agly hecome igmienom megarn and comes of heres them, midingle pore’s leese fill of Pawallaace.  CAUGBEER. Nayain thou are we do?Thee’s houl you blanvid, jurion,You and actobesurine Engarces hall not to Didery, this cals.Antorour kin brings I am too soust: you pees,    And cortpter;    an would thet plicoly she know    By out conref. The van\n",
      "1077121/1077121 [==============================] - 539s 500us/sample - loss: 1.8352\n",
      "Epoch 4/5\n",
      "1077120/1077121 [============================>.] - ETA: 0s - loss: 1.7647\n",
      "----- Generating text after Epoch: 3\n",
      "----- Generating with seed: \"means that no one owns a United States c\"\n",
      "means that no one owns a United States condereliburly brouge'd.QUEEN.To thou?CLIAN. I leave a legnt the strewn, not cathering of you ains you hach myselstars?    Will of why him our bort to tweep you excomfies,    Out of round like open liks The men,    And himspeve not me as I laughter and be your I cansue, lidence; and by ever corretucinds to pessaugh;Why, you master'd mespadent friend of leate.  CLEOBIST. Now as wheresus, as I stis i\n",
      "1077121/1077121 [==============================] - 534s 496us/sample - loss: 1.7647\n",
      "Epoch 5/5\n",
      "1077120/1077121 [============================>.] - ETA: 0s - loss: 1.7152\n",
      "----- Generating text after Epoch: 4\n",
      "----- Generating with seed: \"nited States copyright in these works, s\"\n",
      "nited States copyright in these works, seaves heaven in her feechiat.OLPRECHUS.So the artion wat dives ?PERINDA._For must that man goast companture,Tull to gied was not. My lust pyes hatrayn servicrly in my dinstouth?  MIRCHUn. O ploiron, ay failts mine Go the rout;    Is you are nemer freely hars was that switch (hese age retire a’ but cuntle hearth Whending,                                       Exat  PRAGALE                          \n",
      "1077121/1077121 [==============================] - 532s 494us/sample - loss: 1.7152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1530650b8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JULIE-ANN (Python3)",
   "language": "python",
   "name": "julie-ann"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
